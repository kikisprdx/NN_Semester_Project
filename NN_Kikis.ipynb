{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eadea309-4544-491c-8254-9bdb6b63f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48dec52c-c79b-4ebd-98a8-719957c64380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(filename):\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        current_input = []\n",
    "        current_output = []\n",
    "        # Line by line we strip and split all values \n",
    "        for line in lines:\n",
    "            values = line.strip().split()\n",
    "            # If not the end of a record \n",
    "            if values and values[0] != '1.0':\n",
    "                # We add the whole line (if invalid its going to be set to NaN) \n",
    "                # First 12 set of values are input, the next 12 are output\n",
    "                # I only got this by looking through the original matlab file and inferencing this fact\n",
    "                # I could be wrong so maybe I'll ask the professor \n",
    "                input_values = [float(val) if val else np.nan for val in values[:12]]\n",
    "                output_values = [float(val) if val else np.nan for val in values[12:]]\n",
    "                current_input.append(input_values)\n",
    "                current_output.append(output_values)\n",
    "            # We're at the end\n",
    "            elif values and values[0] == '1.0':\n",
    "                inputs.append(current_input)\n",
    "                outputs.append(current_output)\n",
    "                current_input = []\n",
    "                current_output = []\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "# Read the files\n",
    "train_inputs, train_outputs = read_txt_file('ae.train')\n",
    "test_inputs, test_outputs = read_txt_file('ae.test')\n",
    "\n",
    "train_outputs = []\n",
    "for i in range(269):\n",
    "    speaker_index = (i // 30) + 1  # Assuming 9 speakers, each with 30 time series\n",
    "    l = len(train_inputs[i])\n",
    "    teacher = np.zeros((l, 9))\n",
    "    teacher[:, speaker_index - 1] = 1  # One-hot encoding for speaker index\n",
    "    train_outputs.append(teacher)\n",
    "\n",
    "# Create teacher signals for test data\n",
    "test_outputs = []\n",
    "speaker_index = 1\n",
    "block_counter = 0\n",
    "block_lengths = [31, 35, 88, 44, 29, 24, 40, 50, 29]  # Assuming the same block lengths as in MATLAB code\n",
    "for i in range(370):\n",
    "    block_counter += 1\n",
    "    if block_counter > block_lengths[speaker_index - 1]:\n",
    "        speaker_index += 1\n",
    "        block_counter = 1\n",
    "    l = len(test_inputs[i])\n",
    "    teacher = np.zeros((l, 9))\n",
    "    teacher[:, speaker_index - 1] = 1  # One-hot encoding for speaker index\n",
    "    test_outputs.append(teacher)\n",
    "\n",
    "# READ: Different recording have different lengths \n",
    "# Do we a) shorten the recordings to the shortest one, \n",
    "# b) pad the recordings to the longest one, or\n",
    "# c) something else?\n",
    "# For now I'm doing b) but keep that in mind\n",
    "max_len_train_inputs = max(len(ts) for ts in train_inputs)\n",
    "max_len_train_outputs = max(len(ts) for ts in train_outputs)\n",
    "max_len_test_inputs = max(len(ts) for ts in test_inputs)\n",
    "max_len_test_outputs = max(len(ts) for ts in test_outputs)\n",
    "\n",
    "train_inputs = [np.pad(ts, ((0, max_len_train_inputs - len(ts)), (0, 0)), mode='constant', constant_values=np.nan) for ts in train_inputs]\n",
    "train_outputs = [np.pad(ts, ((0, max_len_train_outputs - len(ts)), (0, 0)), mode='constant', constant_values=np.nan) for ts in train_outputs]\n",
    "test_inputs = [np.pad(ts, ((0, max_len_test_inputs - len(ts)), (0, 0)), mode='constant', constant_values=np.nan) for ts in test_inputs]\n",
    "test_outputs = [np.pad(ts, ((0, max_len_test_outputs - len(ts)), (0, 0)), mode='constant', constant_values=np.nan) for ts in test_outputs]\n",
    "\n",
    "train_inputs = np.array(train_inputs)\n",
    "test_inputs = np.array(test_inputs)\n",
    "train_outputs = np.array(train_outputs)\n",
    "test_outputs = np.array(test_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e12961b3-57fa-44e1-b248-f6a2de78360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.860936 -0.207383  0.261557 ... -0.306756 -0.213076  0.088728]\n",
      "  [ 1.891651 -0.193249  0.235363 ... -0.289431 -0.247722  0.093011]\n",
      "  [ 1.939205 -0.239664  0.258561 ... -0.314894 -0.227908  0.074638]\n",
      "  ...\n",
      "  [ 1.370862 -0.621346  0.600771 ... -0.105327 -0.193044  0.119152]\n",
      "  [ 1.307289 -0.600573  0.620979 ... -0.167528 -0.175811  0.088565]\n",
      "  [ 1.334578 -0.542157  0.558104 ... -0.188285 -0.13861   0.054478]]\n",
      "\n",
      " [[ 1.462484  0.174066  0.505133 ... -0.23763   0.120636  0.193254]\n",
      "  [ 1.309815  0.120183  0.503046 ... -0.231087  0.121053  0.202386]\n",
      "  [ 1.418207  0.015721  0.589994 ... -0.224317  0.175298  0.15667 ]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.160837  0.078806  0.237706 ...  0.028707  0.07482   0.146297]\n",
      "  [ 1.217979 -0.043693  0.378571 ...  0.03897   0.049702  0.164537]\n",
      "  [ 1.234654 -0.107083  0.504189 ...  0.005654 -0.007566  0.168465]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.407858 -0.310496  0.139769 ... -0.139756  0.160754  0.080159]\n",
      "  [ 1.223804 -0.337076  0.086374 ... -0.142101  0.189687  0.120461]\n",
      "  [ 1.034481 -0.296715  0.05072  ... -0.165991  0.235903  0.147237]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.172216  0.137979 -0.170947 ... -0.192855 -0.154419  0.019993]\n",
      "  [ 0.886567  0.002587 -0.082727 ... -0.213924 -0.211937  0.065662]\n",
      "  [ 1.114773 -0.071157 -0.060395 ... -0.216987 -0.217056  0.076721]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.240598 -0.352572  0.202753 ... -0.184956  0.050853  0.061848]\n",
      "  [ 1.227252 -0.313229  0.18586  ... -0.165696  0.032784  0.076978]\n",
      "  [ 1.228334 -0.328534  0.355018 ... -0.184463  0.024559  0.125767]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]]\n",
      "[[[ 1.635533  0.024848  0.432087 ... -0.020431 -0.008612  0.139754]\n",
      "  [ 1.547694  0.008754  0.319101 ... -0.085128  0.030408  0.118123]\n",
      "  [ 1.602593 -0.21052   0.280175 ... -0.093679 -0.004921  0.130402]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.346025 -0.519155  0.651902 ... -0.363407 -0.026334  0.038856]\n",
      "  [ 1.383691 -0.598065  0.647915 ... -0.309786  0.053105  0.041171]\n",
      "  [ 1.405958 -0.555516  0.752111 ... -0.230074  0.070663  0.047138]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.512185 -0.3335    0.471234 ... -0.189616  0.043861  0.071755]\n",
      "  [ 1.65564  -0.391342  0.517804 ... -0.23407   0.050662  0.099892]\n",
      "  [ 1.661793 -0.402195  0.549835 ... -0.234772  0.070845  0.064375]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.505235  0.169987 -0.492503 ... -0.217769  0.094555 -0.03217 ]\n",
      "  [ 1.300354 -0.014071 -0.335232 ... -0.243522  0.102208 -0.020283]\n",
      "  [ 1.232291 -0.108531 -0.255146 ... -0.279655  0.115165  0.049313]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.112425 -0.163326 -0.30761  ... -0.296026  0.012566  0.13597 ]\n",
      "  [ 1.011173 -0.180188 -0.237999 ... -0.267674  0.074387  0.161397]\n",
      "  [ 0.972779 -0.087256 -0.341108 ... -0.304488  0.063687  0.102767]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]\n",
      "\n",
      " [[ 1.421622 -0.386758 -0.187715 ...  0.087146 -0.142142  0.101818]\n",
      "  [ 1.601568 -0.401418 -0.115707 ... -0.017122 -0.111288  0.227841]\n",
      "  [ 1.372168 -0.601565 -0.015212 ... -0.05936  -0.128995  0.195739]\n",
      "  ...\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]\n",
      "  [      nan       nan       nan ...       nan       nan       nan]]]\n",
      "(269, 47, 9)\n",
      "(370, 29, 9)\n"
     ]
    }
   ],
   "source": [
    "# BOOM \n",
    "print(train_inputs)\n",
    "print(test_inputs)\n",
    "print(train_outputs.shape)\n",
    "print(test_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f4ba6295-2fb7-400c-a926-b5bfe684d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_inputs_2d = train_inputs.reshape(-1, 12)  # Flatten the first two dimensions\n",
    "train_inputs_df = pd.DataFrame(train_inputs_2d, columns=[f'feature_{i}' for i in range(1, 13)])\n",
    "train_inputs_df['time_series'] = np.repeat(np.arange(train_inputs.shape[0]), train_inputs.shape[1])\n",
    "train_inputs_df['time_step'] = np.tile(np.arange(train_inputs.shape[1]), train_inputs.shape[0])\n",
    "train_inputs_df_X = train_inputs_df.set_index(['time_series', 'time_step'])\n",
    "train_outputs_2d = train_outputs.reshape(-1, 9)\n",
    "train_outputs_df = pd.DataFrame(train_outputs_2d, columns=[f'speaker_{i}' for i in range(1, 10)])\n",
    "train_outputs_df['time_series'] = np.repeat(np.arange(train_outputs.shape[0]), train_outputs.shape[1])\n",
    "train_outputs_df['time_step'] = np.tile(np.arange(train_outputs.shape[1]), train_outputs.shape[0])\n",
    "train_outputs_df_Y = train_outputs_df.set_index(['time_series', 'time_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f3f7e18f-87e7-48d5-98d1-57db5873692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs_2d = test_inputs.reshape(-1, 12)  # Flatten the first two dimensions\n",
    "test_inputs_df = pd.DataFrame(test_inputs_2d, columns=[f'feature_{i}' for i in range(1, 13)])\n",
    "test_inputs_df['time_series'] = np.repeat(np.arange(test_inputs.shape[0]), test_inputs.shape[1])\n",
    "test_inputs_df['time_step'] = np.tile(np.arange(test_inputs.shape[1]), test_inputs.shape[0])\n",
    "test_inputs_df_X = test_inputs_df.set_index(['time_series', 'time_step'])\n",
    "test_outputs_2d = test_outputs.reshape(-1, 9)\n",
    "test_outputs_df = pd.DataFrame(test_outputs_2d, columns=[f'speaker_{i}' for i in range(1, 10)])\n",
    "test_outputs_df['time_series'] = np.repeat(np.arange(test_outputs.shape[0]), test_outputs.shape[1])\n",
    "test_outputs_df['time_step'] = np.tile(np.arange(test_outputs.shape[1]), test_outputs.shape[0])\n",
    "test_outputs_df_Y = test_outputs_df.set_index(['time_series', 'time_step'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d7951c6-c738-4f02-85f2-d82854d670c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_series</th>\n",
       "      <th>time_step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1.860936</td>\n",
       "      <td>-0.207383</td>\n",
       "      <td>0.261557</td>\n",
       "      <td>-0.214562</td>\n",
       "      <td>-0.171253</td>\n",
       "      <td>-0.118167</td>\n",
       "      <td>-0.277557</td>\n",
       "      <td>0.025668</td>\n",
       "      <td>0.126701</td>\n",
       "      <td>-0.306756</td>\n",
       "      <td>-0.213076</td>\n",
       "      <td>0.088728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.891651</td>\n",
       "      <td>-0.193249</td>\n",
       "      <td>0.235363</td>\n",
       "      <td>-0.249118</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.112238</td>\n",
       "      <td>-0.311997</td>\n",
       "      <td>-0.027122</td>\n",
       "      <td>0.171457</td>\n",
       "      <td>-0.289431</td>\n",
       "      <td>-0.247722</td>\n",
       "      <td>0.093011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.939205</td>\n",
       "      <td>-0.239664</td>\n",
       "      <td>0.258561</td>\n",
       "      <td>-0.291458</td>\n",
       "      <td>-0.041053</td>\n",
       "      <td>-0.102034</td>\n",
       "      <td>-0.383300</td>\n",
       "      <td>0.019013</td>\n",
       "      <td>0.169510</td>\n",
       "      <td>-0.314894</td>\n",
       "      <td>-0.227908</td>\n",
       "      <td>0.074638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.717517</td>\n",
       "      <td>-0.218572</td>\n",
       "      <td>0.217119</td>\n",
       "      <td>-0.228186</td>\n",
       "      <td>-0.018608</td>\n",
       "      <td>-0.137624</td>\n",
       "      <td>-0.403318</td>\n",
       "      <td>-0.009643</td>\n",
       "      <td>0.164607</td>\n",
       "      <td>-0.323267</td>\n",
       "      <td>-0.210105</td>\n",
       "      <td>0.098098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.741191</td>\n",
       "      <td>-0.279891</td>\n",
       "      <td>0.196583</td>\n",
       "      <td>-0.236377</td>\n",
       "      <td>-0.032012</td>\n",
       "      <td>-0.090612</td>\n",
       "      <td>-0.363134</td>\n",
       "      <td>-0.012571</td>\n",
       "      <td>0.124298</td>\n",
       "      <td>-0.351171</td>\n",
       "      <td>-0.216545</td>\n",
       "      <td>0.113899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.684695</td>\n",
       "      <td>-0.311977</td>\n",
       "      <td>0.195453</td>\n",
       "      <td>-0.231970</td>\n",
       "      <td>-0.068670</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.341940</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>0.085097</td>\n",
       "      <td>-0.364329</td>\n",
       "      <td>-0.204794</td>\n",
       "      <td>0.101838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.637373</td>\n",
       "      <td>-0.336227</td>\n",
       "      <td>0.152766</td>\n",
       "      <td>-0.223842</td>\n",
       "      <td>-0.026278</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>-0.363866</td>\n",
       "      <td>-0.003117</td>\n",
       "      <td>0.055479</td>\n",
       "      <td>-0.358107</td>\n",
       "      <td>-0.181643</td>\n",
       "      <td>0.082056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.643283</td>\n",
       "      <td>-0.349773</td>\n",
       "      <td>0.131553</td>\n",
       "      <td>-0.154519</td>\n",
       "      <td>-0.035292</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>-0.381399</td>\n",
       "      <td>-0.021189</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>-0.340491</td>\n",
       "      <td>-0.156417</td>\n",
       "      <td>0.080884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.607030</td>\n",
       "      <td>-0.382745</td>\n",
       "      <td>0.179038</td>\n",
       "      <td>-0.115949</td>\n",
       "      <td>-0.060406</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>-0.364642</td>\n",
       "      <td>-0.069230</td>\n",
       "      <td>-0.019788</td>\n",
       "      <td>-0.355996</td>\n",
       "      <td>-0.115129</td>\n",
       "      <td>0.131928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.617907</td>\n",
       "      <td>-0.527367</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>-0.083292</td>\n",
       "      <td>0.031747</td>\n",
       "      <td>0.081424</td>\n",
       "      <td>-0.418227</td>\n",
       "      <td>-0.081175</td>\n",
       "      <td>-0.022385</td>\n",
       "      <td>-0.337660</td>\n",
       "      <td>-0.103184</td>\n",
       "      <td>0.102266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "time_series time_step                                                          \n",
       "0           0           1.860936  -0.207383   0.261557  -0.214562  -0.171253   \n",
       "            1           1.891651  -0.193249   0.235363  -0.249118  -0.112890   \n",
       "            2           1.939205  -0.239664   0.258561  -0.291458  -0.041053   \n",
       "            3           1.717517  -0.218572   0.217119  -0.228186  -0.018608   \n",
       "            4           1.741191  -0.279891   0.196583  -0.236377  -0.032012   \n",
       "            5           1.684695  -0.311977   0.195453  -0.231970  -0.068670   \n",
       "            6           1.637373  -0.336227   0.152766  -0.223842  -0.026278   \n",
       "            7           1.643283  -0.349773   0.131553  -0.154519  -0.035292   \n",
       "            8           1.607030  -0.382745   0.179038  -0.115949  -0.060406   \n",
       "            9           1.617907  -0.527367   0.179878  -0.083292   0.031747   \n",
       "\n",
       "                       feature_6  feature_7  feature_8  feature_9  feature_10  \\\n",
       "time_series time_step                                                           \n",
       "0           0          -0.118167  -0.277557   0.025668   0.126701   -0.306756   \n",
       "            1          -0.112238  -0.311997  -0.027122   0.171457   -0.289431   \n",
       "            2          -0.102034  -0.383300   0.019013   0.169510   -0.314894   \n",
       "            3          -0.137624  -0.403318  -0.009643   0.164607   -0.323267   \n",
       "            4          -0.090612  -0.363134  -0.012571   0.124298   -0.351171   \n",
       "            5          -0.003822  -0.341940  -0.008826   0.085097   -0.364329   \n",
       "            6          -0.009157  -0.363866  -0.003117   0.055479   -0.358107   \n",
       "            7           0.023719  -0.381399  -0.021189   0.020397   -0.340491   \n",
       "            8           0.057800  -0.364642  -0.069230  -0.019788   -0.355996   \n",
       "            9           0.081424  -0.418227  -0.081175  -0.022385   -0.337660   \n",
       "\n",
       "                       feature_11  feature_12  \n",
       "time_series time_step                          \n",
       "0           0           -0.213076    0.088728  \n",
       "            1           -0.247722    0.093011  \n",
       "            2           -0.227908    0.074638  \n",
       "            3           -0.210105    0.098098  \n",
       "            4           -0.216545    0.113899  \n",
       "            5           -0.204794    0.101838  \n",
       "            6           -0.181643    0.082056  \n",
       "            7           -0.156417    0.080884  \n",
       "            8           -0.115129    0.131928  \n",
       "            9           -0.103184    0.102266  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs_df_X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7706ca72-5241-4186-93c1-cddceb0042d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>speaker_1</th>\n",
       "      <th>speaker_2</th>\n",
       "      <th>speaker_3</th>\n",
       "      <th>speaker_4</th>\n",
       "      <th>speaker_5</th>\n",
       "      <th>speaker_6</th>\n",
       "      <th>speaker_7</th>\n",
       "      <th>speaker_8</th>\n",
       "      <th>speaker_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_series</th>\n",
       "      <th>time_step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       speaker_1  speaker_2  speaker_3  speaker_4  speaker_5  \\\n",
       "time_series time_step                                                          \n",
       "0           0                1.0        0.0        0.0        0.0        0.0   \n",
       "            1                1.0        0.0        0.0        0.0        0.0   \n",
       "            2                1.0        0.0        0.0        0.0        0.0   \n",
       "            3                1.0        0.0        0.0        0.0        0.0   \n",
       "            4                1.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                       speaker_6  speaker_7  speaker_8  speaker_9  \n",
       "time_series time_step                                              \n",
       "0           0                0.0        0.0        0.0        0.0  \n",
       "            1                0.0        0.0        0.0        0.0  \n",
       "            2                0.0        0.0        0.0        0.0  \n",
       "            3                0.0        0.0        0.0        0.0  \n",
       "            4                0.0        0.0        0.0        0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs_df_Y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06a8cf85-6efe-4575-af30-b5bc27c0e3fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, MinMaxScaler\n\u001b[1;32m      2\u001b[0m mm \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      3\u001b[0m ss \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Normalize all values\n",
    "X_ss = ss.fit_transform(train_inputs_df_X)\n",
    "y_mm = mm.fit_transform(train_outputs_df_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c09cd569-abb6-43f5-896b-da828a0513ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs_df.to_csv('train_inputs.csv')\n",
    "train_outputs_df.to_csv('train_outputs.csv')\n",
    "test_inputs_df.to_csv('test_inputs.csv')\n",
    "test_outputs_df.to_csv('test_outputs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0cde0e2c-9c12-4ae6-bab2-9063a1d897c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "from torch.autograd import Variable \n",
    "X = train_inputs_df_X.iloc[:, :].values\n",
    "Y = train_outputs_df_Y.iloc[:, :].values\n",
    "\n",
    "train_X = Variable(torch.Tensor(X))\n",
    "train_Y = Variable(torch.Tensor(Y))\n",
    "\n",
    "#X_train_tensors_final = torch.reshape(train_X,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "#X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc0c77-b05b-437e-9662-6cba3ac9cbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0411c264-43a4-4b57-8a89-46dd687fcae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceIdentificationLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(VoiceIdentificationLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 12\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 10  # Number of unique voices (classes)\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize the model\n",
    "model = VoiceIdentificationLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38179bbd-9d46-4776-92b7-7cfb7da6a8ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m train_inputs, train_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mcombined)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_inputs), batch_size):\n\u001b[0;32m---> 13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m train_outputs[i:i\u001b[38;5;241m+\u001b[39mbatch_size]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/utils/rnn.py:399\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    395\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got numpy.ndarray"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "\n",
    "    # Shuffle the training data\n",
    "    combined = list(zip(train_inputs, train_outputs))\n",
    "    np.random.shuffle(combined)\n",
    "    train_inputs, train_outputs = zip(*combined)\n",
    "\n",
    "    for i in range(0, len(train_inputs), batch_size):\n",
    "        inputs = torch.nn.utils.rnn.pad_sequence([inp for inp in train_inputs[i:i+batch_size]], batch_first=True)\n",
    "        targets = torch.tensor([out[0] for out in train_outputs[i:i+batch_size]], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        epoch_acc += (outputs.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "    epoch_loss /= len(train_inputs)\n",
    "    epoch_acc /= len(train_inputs)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    eval_acc = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_inputs:\n",
    "            inputs = inputs.unsqueeze(0)\n",
    "            targets = torch.tensor([out[0] for out in test_outputs], dtype=torch.long)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            eval_loss += loss.item() * inputs.size(0)\n",
    "            eval_acc += (outputs.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "    eval_loss /= len(test_inputs)\n",
    "    eval_acc /= len(test_inputs)\n",
    "    print(f'Evaluation Loss: {eval_loss:.4f}, Accuracy: {eval_acc:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'voice_identification_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4710d-6b03-47ac-a41d-d2428c7758cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991dabf-7725-437c-b5fb-7d8ddd3ffe5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
